# 4 Convolution
## Solutions to Recommended Problems
### S4.1
The given input in Figure S4.1-1 can be expressed as linear combinations of \(x_{1}[n]\), \(x_{2}[n]\), \(x_{3}[n]\)
> **Figure S4.1-1**
> \(x_1[n]\)
> - Amplitude: 1, -1
> - n range: 0, 1, 2

1.  $$x_{4}[n]=2 x_{1}[n]-2 x_{2}[n]+x_{3}[n]$$
2.  Using superposition, \(y_{4}[n]=2 y_{1}[n]-2 y_{2}[n]+y_{3}[n]\) shown in Figure S4.1-2.
    > **Figure S4.1-2**
    > \(y_4[n]\)
    > - n range: -1, 0, 1
3.  The system is not time-invariant because an input \(x_{1}[n]+x_{1}[n-1]\) does not produce an output \(y_{1}[n]+y_{1}[n-1]\). The input \(x_{1}[n]+x_{1}[n-1]=x_{2}[n]\) (shown in Figure S4.1-3), which we are told produces \(y_{2}[n]\). Since \(y_{2}[n] \neq y_{1}[n]+y_{1}[n-1]\), this system is not time-invariant.
    > **Figure S4.1-3**
    > \(x_1[n]+x_1[n-1]=x_2[n]\)

### S4.2
The required convolutions are most easily done graphically by reflecting \(x[n]\) about the origin and shifting the reflected signal.
1.  By reflecting \(x[n]\) about the origin, shifting, multiplying, and adding, we see that \(y[n]=x[n] * h[n]\) is as shown in Figure S4.2-1.
    > **Figure S4.2-1**
    > \(y[n]\)
    > - Amplitude: 8, 6, 4, 2
    > - n range: 0, 1, 2, 3, 5, 6
2.  By reflecting \(x[n]\) about the origin, shifting, multiplying, and adding, we see that \(y[n]=x[n] * h[n]\) is as shown in Figure S4.2-2.
    > **Figure S4.2-2**
    > \(y[n]\)
    > - Amplitude: 3, 2, 1
    > - n range: 0, 2, 3, 5, 6

Notice that \(y[n]\) is a shifted and scaled version of \(h[n]\).

### S4.3
1.  It is easiest to perform this convolution graphically. The result is shown in Figure S4.3-1.
    > **Figure S4.3-1**
    > \(y(t)=x(t)*h(t)\)
    > - Amplitude: 4
    > - t range: 8
2.  The convolution can be evaluated by using the convolution formula. The limits can be verified by graphically visualizing the convolution.
    $$
    \begin{aligned}
    y(t) & =\int_{-\infty}^{\infty} x(\tau) h(t-\tau) d \tau \\
    & =\int_{-\infty}^{\infty} e^{-(\tau-1)} u(\tau-1) u(t-\tau+1) d \tau \\
    & =\begin{cases}
    \int_{1}^{t+1} e^{-(\tau-1)} d \tau, & t>0, \\
    0, & t<0
    \end{cases}
    \end{aligned}
    $$
    Let \(\tau'=\tau-1\). Then
    $$
    y(t)=\begin{cases}
    \int_{0}^{t} e^{-\tau'} d \tau' = \begin{cases}
    1-e^{-t}, & t>0, \\
    0, & t<0
    \end{cases}
    \end{cases}
    $$
3.  The convolution can be evaluated graphically or by using the convolution formula.
    $$y(t)=\int_{-\infty}^{\infty} x(\tau) \delta(t-\tau-2) d \tau=x(t-2)$$
    So \(y(t)\) is a shifted version of \(x(t)\).
    > **Figure S4.3-2**
    > \(y(t)\)
    > - t range: 1, 5

### S4.4
1.  Since \(y[n]=\sum_{m=-\infty}^{\infty} x[m] h[n-m]\),
    $$y[n]=\sum_{m=-\infty}^{\infty} \delta\left[m-n_{0}\right] h[n-m]=h\left[n-n_{0}\right]$$
    We note that this is merely a shifted version of \(h[n]\).
    > **Figure S4.4-1**
    > \(y[n]=h[n-n_0]\)
2.  $$
    \begin{aligned}
    y[n]&=\sum_{m=-\infty}^{\infty}\left(\frac{1}{2}\right)^{m} u[m] u[n-m] \\
    \text{For }n>0: y[n]&=\sum_{m=0}^{n}\left(\frac{1}{2}\right)^{m}=\frac{1-\left(\frac{1}{2}\right)^{n+1}}{1-\frac{1}{2}}=2\left(1-\left(\frac{1}{2}\right)^{n+1}\right) \\
    y[n]&=2-\left(\frac{1}{2}\right)^{n} \\
    \text{For }n<0: y[n]&=0
    \end{aligned}
    $$
    Here the identity \(\sum_{m=0}^{N-1} a^{m}=\frac{1-a^{N}}{1-a}\) has been used.
    > **Figure S4.4-2**
    > \(y[n]\)
    > - Amplitude: 2, 1.40
    > - n range: 0, 2
3.  Reversing the role of the system and the input has no effect because
    $$y[n]=\sum_{m=-\infty}^{\infty} x[m] h[n-m]=\sum_{m=-\infty}^{\infty} h[m] x[n-m]$$
    The output and sketch are identical to those in part (b).

### S4.5
1.  Using the formula for convolution, we have
    $$
    \begin{aligned}
    y_{1}(t) & =\int_{-\infty}^{\infty} x(\tau) h(t-\tau) d \tau \\
    & =\int_{-\infty}^{\infty} u(\tau) e^{-(t-\tau) / 2} u(t-\tau) d \tau \\
    & =\int_{0}^{t} e^{-(t-\tau) / 2} d \tau, \quad t>0 \\
    & =2 e^{-(t-\tau) / 2}\bigg|_{0}^{t}=2\left(1-e^{-t / 2}\right), \quad t>0 \\
    y(t)&=0, \quad t<0
    \end{aligned}
    $$
    > **Figure S4.5-1**
    > \(y_1(t)\)
    > - Amplitude: 2
    > - t range: 0
2.  Using the formula for convolution, we have
    $$
    \begin{aligned}
    y_{2}(t) & =\int_{0}^{t} 2 e^{-(t-\tau) / 2} d \tau, \quad 3 \geq t \geq 0 \\
    & =4\left(1-e^{-t / 2}\right), \quad 3 \geq t \geq 0 \\
    y_{2}(t) & =\int_{0}^{3} 2 e^{-(t-\tau) / 2} d \tau, \quad t \geq 3 \\
    & =4 e^{-(t-\tau) / 2}\bigg|_{0}^{3}=4\left(e^{-(t-3) / 2}-e^{-t / 2}\right) \\
    & =4 e^{-t / 2}\left(e^{3 / 2}-1\right), \quad t \geq 3 \\
    y_{2}(t)&=0, \quad t \leq 0
    \end{aligned}
    $$
    > **Figure S4.5-2**
    > \(y_2(t)\)
    > - t range: 3, 6
3.  Since \(x_{2}(t)=2[x_{1}(t)-x_{1}(t-3)]\) and the system is linear and time-invariant, \(y_{2}(t)=2[y_{1}(t)-y_{1}(t-3)]\)
    $$
    \begin{aligned}
    \text{For }0 \leq t \leq 3: y_{2}(t)&=2 y_{1}(t)=4\left(1-e^{-t / 2}\right) \\
    \text{For }3 \leq t: y_{2}(t)&=2 y_{1}(t)-2 y_{1}(t-3) \\
    &=4\left(1-e^{-t / 2}\right)-4\left(1-e^{-(t-3) / 2}\right) \\
    &=4 e^{-t / 2}\left[e^{3 / 2}-1\right] \\
    \text{For }t<0: y_{2}(t)&=0
    \end{aligned}
    $$
    We see that this result is identical to the result obtained in part (a)(ii).

## Solutions to Optional Problems
### S4.6
1.  > **Figure S4.6-1**
    > \(x(\tau)\)
    > - Amplitude: 1
    > **Figure S4.6-2**
    > \(h(-1-\tau)\)
    > - Amplitude: 2
    > - \(\tau\) range: -2, 0
    > **Figure S4.6-3**
    > \(h(0-\tau)\)
    > - Amplitude: 2
    > - \(\tau\) range: 0
    > **Figure S4.6-4**
    > \(h(1-\tau)\)
    > - Amplitude: 2
    > - \(\tau\) range: 0, 1
    > **Figure S4.6-5**
    > \(h(2-\tau)\)
    > - Amplitude: 2
    > - \(\tau\) range: 0, 2

    Using these curves, we see that since \(y(t)=x(t) * h(t)\), \(y(t)\) is as shown in Figure S4.6-6.
    > **Figure S4.6-6**
    > \(y(t)\)
    > - Amplitude: 1, 1/2
    > - t range: 0, 1
2.  Consider \(y(t)=x(t) * h(t)=\int_{-\infty}^{\infty} x(t-\tau) h(\tau) d \tau\).
    > **Figure S4.6-7**
    > \(h(\tau)\)
    > - Amplitude: 2
    > - \(\tau\) range: 0, 2
    - For \(0<t<1\) only one impulse contributes.
      > **Figure S4.6-8**
      > \(x(t-\tau)\)
    - For \(1<t<2\) two impulses contribute.
      > **Figure S4.6-9**
      > \(x(t-\tau)\)
    - For \(2<t<3\) two impulses contribute.
      > **Figure S4.6-10**
      > \(x(t-\tau)\)
    - For \(3<t<4\) one impulse contributes.
      > **Figure S4.6-11**
      > \(x(t-\tau)\)
    - For \(t<0\) or \(t>4\) there is no contribution, so \(y(t)\) is as shown in Figure S4.6-12.
      > **Figure S4.6-12**
      > \(y(t)\)
      > - Amplitude: 3, 2, 1
      > - t range: 0, 1, 2, 3, 4

### S4.7
$$
\begin{aligned}
y[n] &=x[n] * h[n] \\
&=\sum_{m=-\infty}^{\infty} x[n-m] h[m] \\
&=\sum_{m=-\infty}^{\infty} \alpha^{n-m} u[n-m] \beta^{m} u[m] \\
&=\sum_{m=0}^{n} \alpha^{n-m} \beta^{m}, \quad n>0 \\
&=\alpha^{n} \sum_{m=0}^{n}\left(\frac{\beta}{\alpha}\right)^{m}=\alpha^{n}\left[\frac{1-(\beta / \alpha)^{n+1}}{1-(\beta / \alpha)}\right] \\
&=\frac{\alpha^{n+1}-\beta^{n+1}}{\alpha-\beta}, \quad n \geq 0 \\
y[n]&=0, \quad n<0
\end{aligned}
$$

### S4.8
1.  \(x(t)=\sum_{k=-\infty}^{\infty} \delta(t-k T)\) is a series of impulses spaced \(T\) apart.
    > **Figure S4.8-1**
    > \(x(t)\)
    > - Amplitude: 1
    > - t range: -2T, -T, 0, T, 2T
2.  Using the result \(x(t) * \delta(t-t_{0})=x(t_{0})\), we have
    > **Figure S4.8-2**
    > Intermediate signal
    > - t range: -1, 0, 1, 2, 3/2
    > **Figure S4.8-3**
    > \(y(t)=x(t)*h(t)\)
    > - Amplitude: 1, 1/2
    > - t range: 0, 1, 2, 3/2

### S4.9
1.  **False**. Counterexample: Let \(g[n]=\delta[n]\). Then
    $$
    \begin{aligned}
    x[n] * \{h[n] g[n]\}&=x[n] * h[0] \\
    \{x[n] * h[n]\} g[n]&=\delta[n] * [x[n] * h[n]]\bigg|_{n=0}
    \end{aligned}
    $$
    and \(x[n]\) may in general differ from \(\delta[n]\).
2.  **True**.
    $$
    \begin{aligned}
    y(2 t)&=\int_{-\infty}^{\infty} x(2 t-\tau) h(\tau) d \tau \\
    \text{Let } \tau'&=\tau / 2. \text{ Then} \\
    y(2 t)&=\int_{-\infty}^{\infty} x\left(2 t-2 \tau'\right) h\left(2 \tau'\right) 2 d \tau' \\
    &=2 x(2 t) * h(2 t)
    \end{aligned}
    $$
3.  **True**.
    $$
    \begin{aligned}
    y(t)&=x(t) * h(t) \\
    y(-t)&=x(-t) * h(-t) \\
    &=\int_{-\infty}^{\infty} x(-t+\tau) h(-\tau) d \tau=\int_{-\infty}^{\infty}[-x(t-\tau)][-h(\tau)] d \tau \\
    &=\int_{-\infty}^{\infty} x(t-\tau) h(\tau) d \tau \quad \text{since } x(\cdot) \text{ and } h(\cdot) \text{ are odd functions} \\
    &=y(t)
    \end{aligned}
    $$
    Hence \(y(t)=y(-t)\), and \(y(t)\) is even.
4.  **False**. Let
    $$
    \begin{aligned}
    x(t)&=\delta(t-1) \\
    h(t)&=\delta(t+1) \\
    y(t)&=\delta(t), \quad Ev\{y(t)\}=\delta(t)
    \end{aligned}
    $$
    Then
    $$
    \begin{aligned}
    x(t) * Ev\{h(t)\}&=\delta(t-1) * \frac{1}{2}[\delta(t+1)+\delta(t-1)] \\
    &=\frac{1}{2}[\delta(t)+\delta(t-2)] \\
    Ev\{x(t)\} * h(t)&=\frac{1}{2}[\delta(t-1)+\delta(t+1)] * \delta(t+1) \\
    &=\frac{1}{2}[\delta(t)+\delta(t+2)]
    \end{aligned}
    $$
    But since \(\frac{1}{2}[\delta(t-2)+\delta(t+2)] \neq 0\),
    $$Ev\{y(t)\} \neq x(t) * Ev\{h(t)\}+Ev\{x(t)\} * h(t)$$

### S4.10
1.  $$
    \begin{aligned}
    \tilde{y}(t)&=\int_{0}^{T_{0}} \tilde{x}_{1}(\tau) \tilde{x}_{2}(t-\tau) d \tau \\
    \tilde{y}\left(t+T_{0}\right)&=\int_{0}^{T_{0}} \tilde{x}_{1}(\tau) \tilde{x}_{2}\left(t+T_{0}-\tau\right) d \tau \\
    &=\int_{0}^{T_{0}} \tilde{x}_{1}(\tau) \tilde{x}_{2}(t-\tau) d \tau=\tilde{y}(t)
    \end{aligned}
    $$
2.  $$
    \begin{aligned}
    \tilde{y}_{a}(t)&=\int_{a}^{a+T_{0}} \tilde{x}_{1}(\tau) \tilde{x}_{2}(t-\tau) d \tau \\
    a&=k T_{0}+b, \quad \text{where } 0 \leq b \leq T_{0} \\
    \tilde{y}_{a}(t)&=\int_{k T_{0}+b}^{(k+1) T_{0}+b} \tilde{x}_{1}(\tau) \tilde{x}_{2}(t-\tau) d \tau \\
    &=\int_{b}^{T_{0}+b} \tilde{x}_{1}(\tau) \tilde{x}_{2}(t-\tau) d \tau, \quad \tau'=\tau-b \\
    &=\int_{b}^{T_{0}} \tilde{x}_{1}(\tau) \tilde{x}_{2}(t-\tau) d \tau+\int_{T_{0}}^{T_{0}+b} \tilde{x}_{1}(\tau) \tilde{x}_{2}(t-\tau) d \tau \\
    &=\int_{b}^{T_{0}} \tilde{x}_{1}(\tau) \tilde{x}_{2}(t-\tau) d \tau+\int_{0}^{b} \tilde{x}_{1}(\tau) \tilde{x}_{2}(t-\tau) d \tau \\
    &=\int_{0}^{T_{0}} \tilde{x}_{1}(\tau) \tilde{x}_{2}(t-\tau) d \tau=\tilde{y}(t)
    \end{aligned}
    $$
3.  For \(0 \leq t \leq \frac{1}{2}\):
    $$
    \begin{aligned}
    \tilde{y}(t)&=\int_{0}^{t} e^{-\tau} d \tau+\int_{1/2+t}^{1} e^{-\tau} d \tau \\
    &=\left(-e^{-\tau}\bigg|_{0}^{t}\right)+\left(-e^{-\tau}\bigg|_{1/2+t}^{1}\right) \\
    &=1 - e^{-t} + e^{-(t+1/2)} - e^{-1} \\
    &=1 - e^{-1} + \left(e^{-1/2} - 1\right)e^{-t}
    \end{aligned}
    $$
    For \(\frac{1}{2} \leq t \leq 1\):
    $$
    \begin{aligned}
    \tilde{y}(t)&=\int_{t-1/2}^{t} e^{-\tau} d \tau \\
    &=e^{-(t-1/2)} - e^{-t} \\
    &=\left(e^{1/2} - 1\right)e^{-t}
    \end{aligned}
    $$
4.  Performing the periodic convolution graphically, we obtain the solution as shown in Figure S4.10-1 and Figure S4.10-2.
    > **Figure S4.10-1**
    > \(\tilde{x}_1[n] * \tilde{x}_2[n]\) (one period)
    > - Amplitude: 2
    > - n range: 0, 1, 3, 4, 5
    > **Figure S4.10-2**
    > \(4\tilde{x}_1[n] * \tilde{x}_2[n]\) (one period)
    > - Amplitude: 4, 2
    > - n range: 0, 1, 11

### S4.11
1.  Since \(y(t)=x(t) * h(t)\) and \(x(t)=g(t) * y(t)\), then \(g(t) * h(t)=\delta(t)\). But
    $$
    \begin{aligned}
    g(t) * h(t)&=\int_{-\infty}^{\infty} \sum_{k=0}^{\infty} g_{k} \delta(t-\tau-k T) \sum_{l=0}^{\infty} h_{l} \delta(\tau-l T) d \tau \\
    &=\sum_{k=0}^{\infty} \sum_{l=0}^{\infty} g_{k} h_{l} \delta(t-(l+k) T)
    \end{aligned}
    $$
    Let \(n=l+k\). Then \(l=n-k\) and
    $$g(t) * h(t)=\sum_{n=0}^{\infty}\left(\sum_{k=0}^{n} g_{k} h_{n-k}\right) \delta(t-n T)$$
    So
    $$
    \sum_{k=0}^{n} g_{k} h_{n-k}=
    \begin{cases}
    1, & n=0 \\
    0, & n \neq 0
    \end{cases}
    $$
    Therefore,
    $$
    \begin{aligned}
    g_{0}&=1/h_{0} \\
    g_{1}&=-h_{1}/h_{0}^{2} \\
    g_{2}&=\frac{-1}{h_{0}}\left(\frac{-h_{1}^{2}}{h_{0}^{2}}+\frac{h_{2}}{h_{0}}\right) \quad ...
    \end{aligned}
    $$
2.  We are given that \(h_{0}=1\), \(h_{1}=\frac{1}{2}\), \(h_{i}=0\) for \(i\geq2\). So
    $$
    \begin{aligned}
    g_{0}&=1 \\
    g_{1}&=-\frac{1}{2} \\
    g_{2}&=+\left(\frac{1}{2}\right)^{2} \\
    g_{3}&=-\left(\frac{1}{2}\right)^{3} \quad ...
    \end{aligned}
    $$
    Therefore,
    $$g(t)=\sum_{k=0}^{\infty}\left(-\frac{1}{2}\right)^{k} \delta(t-k T)$$
3.  (i) Each impulse is delayed by \(T\) and scaled by \(\alpha\) so
    $$h(t)=\sum_{k=0}^{\infty} \alpha^{k} \delta(t-k T)$$
    (ii) If \(0<\alpha<1\), a bounded input produces a bounded output because
    $$
    \begin{aligned}
    y(t)&=x(t) * h(t) \\
    |y(t)|&<\sum_{k=0}^{\infty} \alpha^{k}\left|\int_{-\infty}^{\infty} \delta(\tau-k T) x(t-\tau) d \tau\right| \\
    &<\sum_{k=0}^{\infty} \alpha^{k} \int_{-\infty}^{\infty} \delta(\tau-k T)|x(t-\tau)| d \tau
    \end{aligned}
    $$
    Let \(M=\max|x(t)|\). Then
    $$|y(t)|<M \sum_{k=0}^{\infty} \alpha^{k}=M \frac{1}{1-\alpha}, \quad |\alpha|<1$$
    If \(\alpha>1\), a bounded input will no longer produce a bounded output. For example, consider \(x(t)=u(t)\). Then
    $$
    \begin{aligned}
    y(t)&=\sum_{k=0}^{\infty} \alpha^{k} \int_{-\infty}^{t} \delta(\tau-k T) d \tau \\
    \text{Since } \int_{-\infty}^{t} \delta(\tau-k T) d \tau&=u(t-k T) \\
    y(t)&=\sum_{k=0}^{\infty} \alpha^{k} u(t-k T)
   \end{aligned}
    $$
    Consider, for example, \(t\) equal to (or slightly greater than) \(NT\):
    $$y(NT)=\sum_{k=0}^{N} \alpha^{k}$$
    If \(\alpha>1\), this grows without bound as \(N\) (or \(t\)) increases.
    (iii) Now we want the inverse system. Recognize that we have actually solved this in part (b) of this problem.
    $$
    \begin{aligned}
    g_{0}&=1 \\
    g_{1}&=-\alpha \\
    g_{i}&=0, \quad i \neq 0,1
    \end{aligned}
    $$
    So the system appears as in Figure S4.11.
    > **Figure S4.11**
    > System block diagram
    > - Components: Delay \(T\), multiplier \(-\alpha\)
    > - Input: \(x(t)\), Output: \(y(t)\)
4.  If \(x[n]=\delta[n]\), then \(y[n]=h[n]\). If
    $$x[n]=\frac{1}{2} \delta[n]+\frac{1}{2} \delta[n-N]$$
    then
    $$
    \begin{aligned}
    y[n]&=\frac{1}{2} h[n]+\frac{1}{2} h[n-N] \\
    y[n]&=h[n]
    \end{aligned}
    $$

### S4.12
1.  $$
    \begin{aligned}
    \delta[n]&=\phi[n]-\frac{1}{2} \phi[n-1] \\
    x[n]&=\sum_{k=-\infty}^{\infty} x[k] \delta[n-k]=\sum_{k=-\infty}^{\infty} x[k]\left(\phi[n-k]-\frac{1}{2} \phi[n-k-1]\right) \\
    x[n]&=\sum_{k=-\infty}^{\infty}\left(x[k]-\frac{1}{2} x[k-1]\right) \phi[n-k]
    \end{aligned}
    $$
    So \(a_{k}=x[k]-\frac{1}{2} x[k-1]\).
2.  If \(r[n]\) is the response to \(\phi[n]\), we can use superposition to note that if
    $$x[n]=\sum_{k=-\infty}^{\infty} a_{k} \phi[n-k]$$
    then
    $$y[n]=\sum_{k=-\infty}^{\infty} a_{k} r[n-k]$$
    and, from part (a),
    $$y[n]=\sum_{k=-\infty}^{\infty}\left(x[k]-\frac{1}{2} x[k-1]\right) r[n-k]$$
3.  \(y[n]=\psi[n] * x[n] * r[n]\) when
    $$\psi[n]=\delta[n]-\frac{1}{2} \delta[n-1]$$
    and, from above,
    $$\delta[n]=\phi[n]-\frac{1}{2} \phi[n-1]$$
    So
    $$
    \begin{aligned}
    \psi[n]&=\phi[n]-\frac{1}{2} \phi[n-1]-\frac{1}{2}\left(\phi[n-1]-\frac{1}{2} \phi[n-2]\right) \\
    &=\phi[n]-\phi[n-1]+\frac{1}{4} \phi[n-2]
    \end{aligned}
    $$
4.  \(\phi[n] \to r[n]\), \(\phi[n-1] \to r[n-1]\),
    $$\delta[n]=\phi[n]-\frac{1}{2} \phi[n-1] \to r[n]-\frac{1}{2} r[n-1]$$
    So
    $$h[n]=r[n]-\frac{1}{2} r[n-1]$$
    where \(h[n]\) is the impulse response. Also, from part (c) we know that
    $$y[n]=\psi[n] * x[n] * r[n]$$
    and if \(x[n]=\phi[n]\) produces \(r[n]\), it is apparent that \(\phi[n] * \psi[n]=\delta[n]\).

---
MIT OpenCourseWare
[http://ocw.mit.edu](http://ocw.mit.edu)
Resource: Signals and Systems
Professor Alan V. Oppenheim

The following may not correspond to a particular course on MIT OpenCourseWare, but has been provided by the author as an individual learning resource.

For information about citing these materials or our Terms of Use, visit: [http://ocw.mit.edu/terms](http://ocw.mit.edu/terms)